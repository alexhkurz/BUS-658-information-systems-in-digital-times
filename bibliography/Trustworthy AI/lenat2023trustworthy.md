# Getting from Generative AI to Trustworthy AI: What LLMs might learn from Cyc

**Authors:** Doug Lenat, Gary Marcus  
**Year:** 2023  
**Citation key:** `lenat2023trustworthy`  
**PDF:** [arXiv](https://arxiv.org/pdf/2308.04445.pdf)  
**arXiv:** [2308.04445](https://arxiv.org/abs/2308.04445)  
**Google Scholar:** [search](https://scholar.google.com/scholar?q=Getting+from+Generative+AI+to+Trustworthy+AI+Lenat+Marcus+2023)

## Summary

Lenat and Marcus argue that generative AI (LLMs) is trained to be plausible, not necessarily correct, and is therefore untrustworthy, unstable, and brittle. They lay out **16 desiderata** for future AI and discuss an alternative: AI built with curated explicit knowledge and rules of thumb, plus an inference engine that deduces logical entailmentsâ€”yielding step-by-step, auditable reasoning. The tradeoff is that fully expressive logic is too slow; symbolic systems often use less expressive formalisms (e.g. knowledge graphs). They describe how **Cyc** has addressed this and can reason in higher-order logic in real time. They conclude that trustworthy general AI will require **hybridizing** LLM and formal/symbolic approaches.

## Key concepts

- Trustworthy AI, 16 desiderata
- LLMs: plausible vs correct; untrustworthy, unstable, brittle
- Knowledge, reasoning, world models; common sense
- Cyc, symbolic AI, knowledge graphs, inference engine
- Hybridization of neural and symbolic approaches

## Notes

(To be filled on closer reading.)
