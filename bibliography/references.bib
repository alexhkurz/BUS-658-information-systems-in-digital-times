@inproceedings{vaswani2017,
  author    = {Vaswani, Ashish and Jones, Llion and Shazeer, Noam and Parmar, Niki and Gomez, Aidan N. and Uszkoreit, Jakob and Kaiser, {\L}ukasz and Polosukhin, Illia},
  title     = {{Attention Is All You Need}},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2017},
  volume    = {30},
  url       = {https://arxiv.org/abs/1706.03762},
  note      = {arXiv:1706.03762}
}

@report{hai2024,
  author      = {{Stanford HAI}},
  title       = {{Artificial Intelligence Index Report 2024}},
  institution = {Stanford University Institute for Human-Centered AI},
  year        = {2024},
  url         = {https://hai.stanford.edu/ai-index/2024},
  type        = {Tech.~Rep.}
}

@article{openai2025gdpval,
  author  = {Patwardhan, Tejal and Dias, Rachel and Proehl, Elizabeth and Kim, Grace and Wang, Michele and Watkins, Olivia and {Posada Fishman}, Sim\'on and Aljubeh, Marwan and Thacker, Phoebe and Fauconnet, Laurance and Kim, Natalie S. and Chao, Patrick and Miserendino, Samuel and Chabot, Gildas and Li, David and Sharman, Michael and Barr, Alexandra and Glaese, Amelia and Tworek, Jerry},
  title   = {{GDPval: Evaluating AI Model Performance on Real-World Economically Valuable Tasks}},
  year    = {2025},
  journal = {arXiv preprint},
  url     = {https://arxiv.org/abs/2510.04374},
  note    = {arXiv:2510.04374}
}

@article{lenat2023trustworthy,
  author  = {Lenat, Doug and Marcus, Gary},
  title   = {{Getting from Generative AI to Trustworthy AI: What LLMs might learn from Cyc}},
  year    = {2023},
  journal = {arXiv preprint},
  url     = {https://arxiv.org/abs/2308.04445},
  note    = {arXiv:2308.04445}
}

@inproceedings{french2024,
  author    = {French, Dorothea and D'Mello, Sidney and von der Wense, Katharina},
  title     = {{Aligning to Adults Is Easy, Aligning to Children Is Hard: A Study of Linguistic Alignment in Dialogue Systems}},
  booktitle = {Proceedings of the First Workshop on Human-Centered Large Language Models (HuCLLM)},
  year      = {2024},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2024.hucllm-1.7}
}

@article{ngo2024,
  author  = {Ngo, Richard and Chan, Lawrence and Mindermann, Sören},
  title   = {{The Alignment Problem from a Deep Learning Perspective}},
  journal = {arXiv preprint arXiv:2209.00626},
  year    = {2024},
  eprint  = {2209.00626},
  archivePrefix = {arXiv},
  primaryClass = {cs.AI},
  url     = {https://arxiv.org/abs/2209.00626},
  note    = {Published at ICLR 2024}
}

@inproceedings{kopf2023,
  author    = {Köpf, Andreas and von Rütte, Dimitri and Kilcher, Yannic and Anagnostidis, Sotiris and Barhoum, Abdullah and Duc, Nguyen Minh and Suri, Sameer and Glushkov, David and Tam, Zhi-Rui and Stanley, Oliver and Nagyfi, Richárd and Dantuluri, Arnav and Schuhmann, Christoph and Stevens, Keith and ES, Shahul and Maguire, Andrew and Nguyen, Huu and Mattick, Alexander},
  title     = {{OpenAssistant Conversations - Democratizing Large Language Model Alignment}},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2023},
  volume    = {36},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2023/hash/949f0f8f32267d297c2d4e3ee10a2e7e-Abstract-Datasets_and_Benchmarks.html}
}

@article{hristova2025,
  author  = {Hristova, Tsvetelina and Magee, Liam and Soldatic, Karen},
  title   = {{The problem of alignment}},
  journal = {AI \& SOCIETY},
  year    = {2025},
  volume  = {40},
  pages   = {1439--1453},
  doi     = {10.1007/s00146-024-02039-2},
  url     = {https://doi.org/10.1007/s00146-024-02039-2}
}

@article{mikolov2013,
  author  = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  title   = {{Efficient Estimation of Word Representations in Vector Space}},
  journal = {arXiv preprint arXiv:1301.3781},
  year    = {2013},
  eprint  = {1301.3781},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  url     = {https://arxiv.org/abs/1301.3781}
}

@article{touvron2023,
  author  = {Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and Bikel, Dan and Blecher, Lukas and Ferrer, Cristian Canton and Chen, Moya and Cucurull, Guillem and Esiobu, David and Fernandes, Jude and Fu, Jeremy and Fu, Wenyin and Fuller, Brian and Gao, Cynthia and Goswami, Vedanuj and Goyal, Naman and Hartshorn, Anthony and Hosseini, Saghar and Hou, Rui and Inan, Hakan and Kardas, Marcin and Kerkez, Viktor and Khabsa, Madian and Kloumann, Isabel and Korenev, Artem and Koura, Punit Singh and Lachaux, Marie-Anne and Lavril, Thibaut and Lee, Jenya and Liskovich, Diana and Lu, Yinghai and Mao, Yuning and Martinet, Xavier and Mihaylov, Todor and Mishra, Pushkar and Molybog, Igor and Nie, Yixin and Poulton, Andrew and Reizenstein, Jeremy and Rungta, Rashi and Saladi, Kalyan and Schelten, Alan and Silva, Ruan and Smith, Eric Michael and Subramanian, Ranjan and Tan, Xiaoqing Ellen and Tang, Binh and Taylor, Ross and Williams, Adina and Kuan, Jian Xiang and Xu, Puxin and Yan, Zheng and Zarov, Iliyan and Zhang, Yuchen and Fan, Angela and Kambadur, Melanie and Narang, Sharan and Rodriguez, Aurelien and Stojnic, Robert and Edunov, Sergey and Scialom, Thomas},
  title   = {{Llama 2: Open Foundation and Fine-Tuned Chat Models}},
  journal = {arXiv preprint arXiv:2307.09288},
  year    = {2023},
  eprint  = {2307.09288},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  url     = {https://arxiv.org/abs/2307.09288}
}

@techreport{radford2018,
  author      = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
  title       = {{Improving Language Understanding by Generative Pre-Training}},
  institution = {OpenAI},
  year        = {2018},
  url         = {https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf}
}

@inproceedings{wei2022,
  author    = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed H. and Le, Quoc V. and Zhou, Denny},
  title     = {{Chain-of-Thought Prompting Elicits Reasoning in Large Language Models}},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2022},
  volume    = {35},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html}
}

@article{shannon1951,
  author  = {Shannon, C. E.},
  title   = {{Prediction and Entropy of Printed English}},
  journal = {Bell System Technical Journal},
  year    = {1951},
  volume  = {30},
  number  = {1},
  pages   = {50--64},
  doi     = {10.1002/j.1538-7305.1951.tb01366.x}
}

@article{taylor1953,
  author  = {Taylor, Wilson L.},
  title   = {{"Cloze Procedure": A New Tool for Measuring Readability}},
  journal = {Journalism Quarterly},
  year    = {1953},
  volume  = {30},
  number  = {4},
  pages   = {415--433},
  doi     = {10.1177/107769905303000401}
}

@article{sun2025,
  author  = {Sun, Huaman and Pei, Jiaxin and Choi, Minje and Jurgens, David},
  title   = {{Sociodemographic Prompting is Not Yet an Effective Approach for Simulating Subjective Judgments with LLMs}},
  journal = {arXiv preprint arXiv:2311.09730},
  year    = {2025},
  eprint  = {2311.09730},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  url     = {https://arxiv.org/abs/2311.09730}
}

@article{gao2025,
  author  = {Gao, Yuan and Lee, Dokyun and Burtch, Gordon and Fazelpour, Sina},
  title   = {{Take Caution in Using LLMs as Human Surrogates: Scylla Ex Machina}},
  journal = {arXiv preprint arXiv:2410.19599},
  year    = {2025},
  eprint  = {2410.19599},
  archivePrefix = {arXiv},
  primaryClass = {econ.GN},
  url     = {https://arxiv.org/abs/2410.19599}
}

@article{binz2025,
  author  = {Binz, Marcel and Akata, Elif and Bethge, Matthias and Brändle, Franziska and Callaway, Fred and Coda-Forno, Julian and Dayan, Peter and Demircan, Can and Eckstein, Maria K. and Éltető, Noémi and Griffiths, Thomas L. and Haridi, Susanne and Jagadish, Akshay K. and Ji-An, Li and Kipnis, Alexander and Kumar, Sreejan and Ludwig, Tobias and Mathony, Marvin and Mattar, Marcelo and Modirshanechi, Alireza and Nath, Surabhi S. and Peterson, Joshua C. and Rmus, Milena and Russek, Evan M. and Saanum, Tankred and Schubert, Johannes A. and Schulze Buschoff, Luca M. and Singhi, Nishad and Sui, Xin and Thalmann, Mirko and Theis, Fabian and Truong, Vuong and Voudouris, Konstantinos and Wilson, Robert and Witte, Kristin and Wu, Shuchen and Wulff, Dirk U. and Xiong, Huadong and Schulz, Eric},
  title   = {{Centaur: a foundation model of human cognition}},
  journal = {arXiv preprint arXiv:2410.20268},
  year    = {2025},
  eprint  = {2410.20268},
  archivePrefix = {arXiv},
  primaryClass = {cs.LG},
  url     = {https://arxiv.org/abs/2410.20268}
}

@article{anthis2025,
  author  = {Anthis, Jacy R. and Liu, Ryan and Richardson, Sean M. and Kozlowski, Austin C. and Koch, Bernard and Brynjolfsson, Erik and Evans, James and Bernstein, Michael S.},
  title   = {{Position: LLM Social Simulations Are a Promising Research Method}},
  journal = {arXiv preprint arXiv:2504.02234},
  year    = {2025},
  eprint  = {2504.02234},
  archivePrefix = {arXiv},
  primaryClass = {cs.HC},
  url     = {https://arxiv.org/abs/2504.02234}
}

@article{manning2025,
  author  = {Manning, Benjamin S. and Horton, John J.},
  title   = {{General Social Agents}},
  journal = {arXiv preprint arXiv:2508.17407},
  year    = {2025},
  eprint  = {2508.17407},
  archivePrefix = {arXiv},
  primaryClass = {econ.GN},
  url     = {https://arxiv.org/abs/2508.17407}
}

@article{jackson2025,
  author  = {Jackson, Matthew O. and Mei, Qiaozhu and Wang, Stephanie W. and Xie, Yutong and Yuan, Walter and Benzell, Seth and Brynjolfsson, Erik and Camerer, Colin F. and Evans, James and Jabarian, Brian and Kleinberg, Jon and Meng, Juanjuan and Mullainathan, Sendhil and Ozdaglar, Asuman and Pfeiffer, Thomas and Tennenholtz, Moshe and Willer, Robb and Yang, Diyi and Ye, Teng},
  title   = {{AI Behavioral Science}},
  journal = {arXiv preprint arXiv:2509.13323},
  year    = {2025},
  eprint  = {2509.13323},
  archivePrefix = {arXiv},
  primaryClass = {cs.HC},
  url     = {https://arxiv.org/abs/2509.13323}
}

@article{hewitt2024,
  author  = {Hewitt, Luke and Ashokkumar, Ashwini and Ghezae, Isaias and Willer, Robb},
  title   = {{Predicting Results of Social Science Experiments Using Large Language Models}},
  year    = {2024},
  journal = {Preprint},
  url     = {https://treatmenteffect.app/supplement.pdf},
  note    = {August 8, 2024; supplement and web demo at treatmenteffect.app}
}

@article{tranchero2025,
  author  = {Tranchero, Matteo and Brenninkmeijer, Cecil-Francis and Murugan, Arul and Nagaraj, Abhishek},
  title   = {{Theorizing with Large Language Models}},
  year    = {2025},
  journal = {SSRN},
  number  = {4836620},
  url     = {https://ssrn.com/abstract=4836620},
  note    = {July 31, 2025}
}

@article{charness2025,
  author  = {Charness, Gary and Jabarian, Brian and List, John A.},
  title   = {{The next generation of experimental research with LLMs}},
  journal = {Nature Human Behaviour},
  year    = {2025},
  doi     = {10.1038/s41562-025-02137-1},
  url     = {https://doi.org/10.1038/s41562-025-02137-1}
}

@article{li2023,
  author  = {Li, Peiyao and Castelo, Noah and Katona, Zsolt and Sarvary, Miklos},
  title   = {{Determining the Validity of Large Language Models for Automated Perceptual Analysis}},
  year    = {2023},
  journal = {SSRN},
  number  = {4241291},
  url     = {https://ssrn.com/abstract=4241291}
}

@inproceedings{wang2022scienceworld,
  author    = {Wang, Ruoyao and Jansen, Peter and C{\^o}t{\'e}, Marc-Alexandre and Ammanabrolu, Prithviraj},
  title     = {{Science World: Is your Agent Smarter than a 5th Grader?}},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year      = {2022},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2022.emnlp-main.775}
}

@inproceedings{xi2025,
  author    = {Xi, Zhiheng and Ding, Yiwen and Chen, Wenxiang and Hong, Boyang and Guo, Honglin and Wang, Junzhe and Guo, Xin and Yang, Dingwen and Liao, Chenyang and He, Wei and Gao, Songyang and Chen, Lu and Zheng, Rui and Zou, Yicheng and Gui, Tao and Zhang, Qi and Qiu, Xipeng and Huang, Xuanjing and Wu, Zuxuan and Jiang, Yu-Gang},
  title     = {{Agent Gym: Evaluating and Training Large Language Model-based Agents across Diverse Environments}},
  booktitle = {Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (ACL)},
  year      = {2025},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2025.acl-long.1355}
}

@article{shumailov2023,
  author  = {Shumailov, Ilia and Shumaylov, Zakhar and Papernot, Nicolas and Zhao, Yiren and Gal, Yarin and Anderson, Ross},
  title   = {{The Curse of Recursion: Training on Generated Data Makes Models Forget}},
  journal = {arXiv preprint arXiv:2305.17493},
  year    = {2023},
  eprint  = {2305.17493},
  archivePrefix = {arXiv},
  primaryClass = {cs.LG},
  url     = {https://arxiv.org/abs/2305.17493}
}

@article{kaplan2020,
  author  = {Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B. and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  title   = {{Scaling Laws for Neural Language Models}},
  journal = {arXiv preprint arXiv:2001.08361},
  year    = {2020},
  eprint  = {2001.08361},
  archivePrefix = {arXiv},
  primaryClass = {cs.LG},
  url     = {https://arxiv.org/abs/2001.08361}
}

@article{bernerslee2001,
  author  = {Berners-Lee, Tim and Hendler, James and Lassila, Ora},
  title   = {{The Semantic Web}},
  journal = {Scientific American},
  year    = {2001},
  volume  = {284},
  number  = {5},
  pages   = {34--43},
  month   = may,
  url     = {https://www.scientificamerican.com/article/the-semantic-web}
}

@article{valmeekam2023,
  author  = {Valmeekam, Chandra Shekhara Kaushik and Narayanan, Krishna and Kalathil, Dileep and Chamberland, Jean-Francois and Shakkottai, Srinivas},
  title   = {{LLMZip: Lossless Text Compression using Large Language Models}},
  journal = {arXiv preprint arXiv:2306.04050},
  year    = {2023},
  eprint  = {2306.04050},
  archivePrefix = {arXiv},
  primaryClass = {cs.IT},
  url     = {https://arxiv.org/abs/2306.04050}
}

@inproceedings{deletang2024,
  author    = {Del{\'e}tang, Gr{\'e}goire and Ruoss, Anian and Genewein, Tim and Mattern, Christopher and Aitchison, Matthew and Duquenne, Paul-Ambroise and Grau-Moya, Jordi and Orseau, Laurent and Hutter, Marcus and Catt, Elliot and Wenliang, Li Kevin and Veness, Joel},
  title     = {{Language Modeling Is Compression}},
  booktitle = {Proceedings of the 12th International Conference on Learning Representations (ICLR)},
  year      = {2024},
  url       = {https://arxiv.org/abs/2309.10668},
  eprint    = {2309.10668},
  archivePrefix = {arXiv},
  primaryClass = {cs.LG}
}

@article{tsai2026,
  author  = {Tsai, Chen-Han},
  title   = {{Revisiting Data Compression with Language Modeling}},
  journal = {arXiv preprint arXiv:2601.02875},
  year    = {2026},
  eprint  = {2601.02875},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  url     = {https://arxiv.org/abs/2601.02875}
}

@article{dantas2025,
  author  = {Dantas, Pierre V. and Cordeiro, Lucas C. and Junior, Waldir S. S.},
  title   = {{A review of state-of-the-art techniques for large language model compression}},
  journal = {Complex \& Intelligent Systems},
  year    = {2025},
  volume  = {11},
  pages   = {407--},
  doi     = {10.1007/s40747-025-02019-z},
  url     = {https://doi.org/10.1007/s40747-025-02019-z}
}

@article{li2025,
  author  = {Li, Ziguang and Huang, Chao and Wang, Xuliang and Hu, Haibo and Wyeth, Cole and Bu, Dongbo and Yu, Quan and Gao, Wen and Liu, Xingwu and Li, Ming},
  title   = {{Lossless data compression by large models}},
  journal = {Nature Machine Intelligence},
  year    = {2025},
  volume  = {7},
  pages   = {794--799},
  doi     = {10.1038/s42256-025-01033-7},
  url     = {https://doi.org/10.1038/s42256-025-01033-7}
}

@article{zhu2025,
  author  = {Zhu, Xunyu and Li, Jian and Liu, Yong and Ma, Can and Wang, Weiping},
  title   = {{A Survey on Model Compression for Large Language Models}},
  journal = {Transactions of the Association for Computational Linguistics},
  year    = {2025},
  url     = {https://aclanthology.org/},
  note    = {TACL}
}

@article{papadimitriou2010,
  author  = {Papadimitriou, C. and Karamanos, K. and Diakonos, F.K. and Constantoudis, V. and Papageorgiou, H.},
  title   = {{Entropy analysis of natural language written texts}},
  journal = {Physica A},
  year    = {2010},
  volume  = {389},
  pages   = {3260--3266},
  doi     = {10.1016/j.physa.2010.03.038},
  url     = {https://doi.org/10.1016/j.physa.2010.03.038}
}

@article{bentz2016,
  author  = {Bentz, Christian and Alikaniotis, Dimitrios},
  title   = {{The Word Entropy of Natural Languages}},
  journal = {arXiv preprint arXiv:1606.06996},
  year    = {2016},
  eprint  = {1606.06996},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  url     = {https://arxiv.org/abs/1606.06996}
}

@inproceedings{nguyen2025,
  author    = {Nguyen, Dang and Payani, Ali},
  title     = {{Beyond Semantic Entropy: Boosting LLM Uncertainty Quantification with Pairwise Semantic Similarity}},
  booktitle = {Findings of the Association for Computational Linguistics: ACL 2025},
  year      = {2025},
  pages     = {4530--4540},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2025.findings-acl.234}
}

@article{vonzurgathen2018,
  author  = {von zur Gathen, Joachim and Loebenberger, Daniel},
  title   = {{Why One Cannot Estimate the Entropy of English by Sampling}},
  journal = {Journal of Quantitative Linguistics},
  year    = {2018},
  volume  = {25},
  number  = {1},
  pages   = {77--106},
  doi     = {10.1080/09296174.2017.1341724},
  url     = {https://doi.org/10.1080/09296174.2017.1341724}
}

@article{rosillo2025,
  author  = {Rosillo-Rodes, Pablo and San Miguel, Maxi and S{\'a}nchez, David},
  title   = {{Entropy and type-token ratio in gigaword corpora}},
  journal = {Physical Review Research},
  year    = {2025},
  volume  = {7},
  pages   = {033054},
  doi     = {10.1103/PhysRevResearch.7.033054},
  url     = {https://doi.org/10.1103/PhysRevResearch.7.033054}
}
