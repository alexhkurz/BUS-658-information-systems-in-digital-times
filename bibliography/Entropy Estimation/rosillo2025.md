# Entropy and type-token ratio in gigaword corpora

**Authors:** Pablo Rosillo-Rodes, Maxi San Miguel, David Sánchez  
**Year:** 2025  
**Citation key:** `rosillo2025`  
**PDF:** [Physical Review Research](https://doi.org/10.1103/PhysRevResearch.7.033054)  
**Google Scholar:** [Search](https://scholar.google.com/scholar?q=Entropy+and+type-token+ratio+in+gigaword+corpora)

## Summary

Lexical diversity in language can be measured by type-token ratio (TTR) and word entropy. The paper studies both metrics on six large corpora (English, Spanish, Turkish) across books, news, and tweets. An empirical functional relation between entropy and TTR is found for texts within a corpus and language, stemming from statistical laws of natural language. In the limit of large text length, an analytical expression for this relation is derived from Zipf’s and Heaps’ laws, consistent with the data.

## Authors

**Pablo Rosillo-Rodes, Maxi San Miguel, David Sánchez** — Institute for Cross-Disciplinary Physics and Complex Systems (IFISC), UIB-CSIC, Palma de Mallorca, Spain. Research in complex systems, quantitative linguistics, and statistical laws of language.

## Relevance to our class

- **Entropy and lexical diversity**: TTR vs entropy; Zipf and Heaps as grounding for analytical relations.
- **Cross-linguistic and register variation**: morphology, genre, register in large corpora.
- **Statistical physics of language**: scaling, limit behaviour, and empirical validation.

## Key concepts

- **Type-token ratio**, word entropy, Zipf’s law, Heaps’ law, gigaword corpora, lexical diversity, scaling.

## Notes

(Quotes, reading notes, follow-ups)
