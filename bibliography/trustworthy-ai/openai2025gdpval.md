# GDPval: Evaluating AI Model Performance on Real-World Economically Valuable Tasks

**Authors:** Tejal Patwardhan, Rachel Dias, Elizabeth Proehl, Grace Kim, Michele Wang, Olivia Watkins, Simón Posada Fishman, Marwan Aljubeh, Phoebe Thacker, Laurance Fauconnet, Natalie S. Kim, Patrick Chao, Samuel Miserendino, Gildas Chabot, David Li, Michael Sharman, Alexandra Barr, Amelia Glaese, Jerry Tworek (OpenAI)  
**Year:** 2025  
**Citation key:** `openai2025gdpval`  
**PDF:** [arXiv](https://arxiv.org/pdf/2510.04374.pdf)  
**arXiv:** [2510.04374](https://arxiv.org/abs/2510.04374)  
**Google Scholar:** [search](https://scholar.google.com/scholar?q=GDPval+OpenAI+2025+economically+valuable+tasks)

## Summary

OpenAI introduces GDPval, a benchmark that evaluates AI model performance on real-world, economically valuable tasks. It covers the majority of U.S. BLS Work Activities for 44 occupations across the top 9 sectors contributing to U.S. GDP. Tasks are built from work product of industry professionals (average 14 years experience). Main findings: frontier model performance on GDPval is improving roughly linearly; current best frontier models are approaching industry experts in deliverable quality; the paper analyzes potential for frontier models with human oversight to perform tasks cheaper and faster than unaided experts. Increased reasoning effort, task context, and scaffolding improve performance. OpenAI open-sources a gold subset of 220 tasks and provides a public automated grading service at evals.openai.com. The benchmark is designed to be a leading indicator of AI’s economic impact, complementing lagging indicators like adoption and GDP.

## Key concepts

- GDPval, benchmark, economically valuable tasks
- O*NET, Work Activities, occupations, sectors
- Head-to-head human expert comparison, win rate
- Realism, representative breadth, computer use, multi-modality
- Evaluation saturation; automated grading; evals.openai.com

## Notes

(To be filled on closer reading.)
