# Theorizing with Large Language Models

**Authors:** Matteo Tranchero, Cecil-Francis Brenninkmeijer, Arul Murugan, Abhishek Nagaraj  
**Year:** 2025  
**Citation key:** `tranchero2025`  
**PDF:** [SSRN](https://ssrn.com/abstract=4836620)  
**Code:** [GitHub](https://github.com/arulmabr/theorizing_with_llms)  
**Google Scholar:** [Search](https://scholar.google.com/scholar?q=Theorizing+Large+Language+Models+Tranchero+2025)

## Summary

This paper shows how AI can support theory development in management and strategy by simulating experiments using LLMs as synthetic subjects. The authors introduce a structured framework to standardise the design and execution of in silico experiments with LLM-powered agents, arguing that this approach blends the realism of human-subject data with the computational control of agent-based models. They apply the framework to the classic exploration–exploitation dilemma in strategy, showing that LLM simulations reproduce "ground truth" results from human participants. They then demonstrate how LLM agents can be used to generate new hypotheses, investigate mechanisms, and test boundary conditions. The paper concludes by discussing the promise and limitations of this methodological innovation and how it can complement existing approaches in management research.

## Authors

**Matteo Tranchero** — University of Pennsylvania (Wharton). Equal contribution. Email: mtranc@wharton.upenn.edu. Research in strategy and innovation.

**Abhishek Nagaraj** — University of California, Berkeley. Equal contribution, corresponding author. Email: nagaraj@berkeley.edu. Research in strategy, innovation, and data-driven methods. [Google Scholar](https://scholar.google.com/citations?user=WqF5qVYAAAAJ)

**Cecil-Francis Brenninkmeijer** — University of California, Berkeley. Research in strategy and organisational behaviour.

**Arul Murugan** — University of California, Berkeley. Research in strategy and computational methods.

## Relevance to our project

### Theory Building with LLMs
- Focus on theory development, not only prediction or replication
- Framework for in silico experiments with LLM agents
- Relevant to methodology of management and strategy research

### Exploration–Exploitation
- Applies framework to classic strategy dilemma
- Shows LLM simulations match human experimental results
- Demonstrates extension to new hypotheses, mechanisms, boundary conditions

### Balance of Realism and Control
- Positions LLM experiments between agent-based models (control) and human experiments (realism)
- Analogous to "model organisms" in biomedical research
- Relevant to when LLM data can substitute for or complement human data

### Management and Strategy
- Targets management and organisational research audience
- Complements economics/psychology-focused LLM simulation work
- Opens discussion of LLMs in business research

## Key concepts

- **In silico experiments**: Experiments run with computational (LLM) subjects
- **Silicon sampling**: Using LLMs as proxies for human behaviour
- **Exploration–exploitation**: Classic strategy trade-off between known and new options
- **Ground truth**: Human participant results used to validate LLM simulations

## Notes

The paper explicitly analogises LLM subjects to model organisms—allowing researchers to refine theories before costly human testing. The framework is designed to be reusable across strategy problems. The authors acknowledge support from OpenAI (computing credits) and limitations of the approach. Code is available on GitHub (e.g. streetlight_no-data notebook). Useful for courses on strategy, innovation, or research methods.
