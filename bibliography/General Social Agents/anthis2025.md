# Position: LLM Social Simulations Are a Promising Research Method

**Authors:** Jacy R. Anthis, Ryan Liu, Sean M. Richardson, Austin C. Kozlowski, Bernard Koch, Erik Brynjolfsson, James Evans, Michael S. Bernstein  
**Year:** 2025  
**Citation key:** `anthis2025`  
**PDF:** [arXiv](https://arxiv.org/pdf/2504.02234.pdf)  
**arXiv:** [2504.02234](https://arxiv.org/abs/2504.02234)  
**Google Scholar:** [Search](https://scholar.google.com/scholar?q=Position+LLM+Social+Simulations+Promising+Research+Method+Anthis+2025)

## Summary

This position paper argues that LLM social simulations are a promising research method that can be improved by addressing five tractable challenges: diversity, bias, sycophancy, alienness, and generalisation. The authors ground their argument in a review of empirical comparisons between LLMs and human research subjects, commentaries, and related work. They identify promising directions including context-rich prompting and fine-tuning with social science datasets. The paper cites compelling simulation results, including Hewitt et al. (2024) where GPT-4 predicted 91% of variation in average treatment effects across 70 preregistered experiments, and Binz et al. (2024) where a fine-tuned model outperformed existing cognitive models. The authors believe LLM social simulations can already be used for pilot and exploratory studies, with more widespread use possible as LLM capabilities advance. They recommend researchers prioritise developing conceptual models and iterative evaluations.

## Authors

**Jacy R. Anthis** — University of Chicago, Stanford University, Sentience Institute. Corresponding author. Email: anthis@uchicago.edu. Research in social science, AI, and effective altruism.

**Erik Brynjolfsson** — Stanford University. Professor at Stanford Institute for Human-Centered AI. Research in economics of technology, productivity, and AI. [Homepage](https://www.gsb.stanford.edu/faculty-research/faculty/erik-brynjolfsson) | [Google Scholar](https://scholar.google.com/citations?user=Gq3QqJYAAAAJ)

**James Evans** — University of Chicago and Santa Fe Institute. Professor of Sociology. Research in computational social science, knowledge production, and AI. [Homepage](https://home.uchicago.edu/~jevans/) | [Google Scholar](https://scholar.google.com/citations?user=WqF5qVYAAAAJ)

**Michael S. Bernstein** — Stanford University. Associate Professor of Computer Science. Research in human-computer interaction, social computing, and AI. [Homepage](https://hci.stanford.edu/msb/) | [Google Scholar](https://scholar.google.com/citations?user=zJqJqJYAAAAJ)

**Ryan Liu, Sean M. Richardson, Austin C. Kozlowski, Bernard Koch** — University of Chicago researchers in computational social science.

## Relevance to our project

### Optimistic Perspective on LLM Simulations
- Provides balanced, constructive view of LLM social simulations
- Identifies specific challenges and promising solutions
- Relevant to understanding potential benefits and limitations

### Five Key Challenges
- **Diversity**: Generic outputs lacking human variation
- **Bias**: Systematic inaccuracies for particular groups
- **Sycophancy**: Overly user-pleasing outputs
- **Alienness**: Superficially accurate but non-humanlike mechanisms
- **Generalisation**: Failures in out-of-distribution contexts

### Promising Directions
- Context-rich prompting (e.g., interview-based)
- Fine-tuning on social science datasets
- Steering vectors and other technical interventions
- Iterative evaluation and validation

### Practical Applications
- Already useful for pilot and exploratory studies
- Potential for accelerating social science research
- Could enable exploration of counterfactuals and policy scenarios

## Key concepts

- **LLM social simulations**: Using LLMs to simulate human research subjects
- **Diversity challenge**: Need for humanlike variation in outputs
- **Bias challenge**: Systematic inaccuracies when simulating particular groups
- **Sycophancy**: Tendency to excessively please users rather than simulate accurately
- **Alienness**: Superficially correct results generated through non-humanlike processes
- **Generalisation challenge**: Maintaining accuracy in novel contexts

## Notes

This position paper provides a balanced, constructive perspective on LLM social simulations. Unlike purely critical papers, it acknowledges both limitations and potential. The five challenges framework provides useful structure for thinking about when and how to use LLMs as social agents. The paper cites impressive results (e.g., 91% variance explained in treatment effects) whilst acknowledging that most studies haven't used the full range of available methods. The recommendation to prioritise conceptual models and iterative evaluation is particularly important—it suggests that successful use requires careful methodology, not just better models. This paper complements more critical work (like Gao et al.) by showing a path forward.
