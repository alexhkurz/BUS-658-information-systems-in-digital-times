# Centaur: a foundation model of human cognition

**Authors:** Marcel Binz, Elif Akata, Matthias Bethge, Franziska Brändle, Fred Callaway, Julian Coda-Forno, Peter Dayan, Can Demircan, Maria K. Eckstein, Noémi Éltető, Thomas L. Griffiths, Susanne Haridi, Akshay K. Jagadish, Li Ji-An, Alexander Kipnis, Sreejan Kumar, Tobias Ludwig, Marvin Mathony, Marcelo Mattar, Alireza Modirshanechi, Surabhi S. Nath, Joshua C. Peterson, Milena Rmus, Evan M. Russek, Tankred Saanum, Johannes A. Schubert, Luca M. Schulze Buschoff, Nishad Singhi, Xin Sui, Mirko Thalmann, Fabian Theis, Vuong Truong, Vishaal Udandarao, Konstantinos Voudouris, Robert Wilson, Kristin Witte, Shuchen Wu, Dirk U. Wulff, Huadong Xiong, Eric Schulz  
**Year:** 2025  
**Citation key:** `binz2025`  
**PDF:** [arXiv](https://arxiv.org/pdf/2410.20268.pdf)  
**arXiv:** [2410.20268](https://arxiv.org/abs/2410.20268)  
**Google Scholar:** [Search](https://scholar.google.com/scholar?q=Centaur+foundation+model+human+cognition+Binz+2025)

## Summary

This paper introduces Centaur, a computational model designed to predict and simulate human behavior across a wide range of psychological experiments expressible in natural language. Centaur is derived by fine-tuning a state-of-the-art language model on Psych-101, a novel large-scale dataset covering trial-by-trial data from over 60,000 participants performing over 10,000,000 choices across 160 experiments spanning decision-making, memory, learning, and other cognitive domains. Centaur not only captures the behavior of held-out participants better than existing cognitive models but also generalises to new cover stories, structural task modifications, and entirely new domains. Furthermore, the model's internal representations become more aligned with human neural activity after fine-tuning. The authors argue that such unified models provide tremendous potential for guiding the development of cognitive theories and represent a step towards a unified theory of cognition.

## Authors

**Marcel Binz** — Helmholtz Munich. Corresponding author. Email: marcel.binz@helmholtz-munich.de. Research in cognitive science, computational modelling, and machine learning.

**Eric Schulz** — Helmholtz Munich. Research in cognitive science, computational modelling, and decision-making.

**Thomas L. Griffiths** — Princeton University. Professor of Psychology and Computer Science. Research in computational cognitive science, Bayesian models, and human learning. [Homepage](https://cocosci.princeton.edu/tom/) | [Google Scholar](https://scholar.google.com/citations?user=YqLqj5YAAAAJ)

**Peter Dayan** — Max Planck Institute for Biological Cybernetics and University of Tübingen. Research in computational neuroscience, reinforcement learning, and decision-making.

**Large collaborative team** — Authors from multiple institutions including Helmholtz Munich, University of Tübingen, Max Planck Institute, Princeton, NYU, Google DeepMind, and others.

## Relevance to our project

### Unified Models of Cognition
- Demonstrates feasibility of building general models that predict human behavior across domains
- Addresses long-standing goal of unified theory of cognition
- Relevant to discussions of whether AI can capture human cognitive processes

### LLMs as Cognitive Models
- Shows that fine-tuning LLMs on psychological data improves their ability to predict human behavior
- Demonstrates alignment between model representations and neural activity
- Relevant to understanding relationship between language models and human cognition

### Generalisation and Transfer
- Shows model generalises to new tasks, cover stories, and domains
- Demonstrates value of large-scale datasets for cognitive modelling
- Relevant to discussions of when models can generalise beyond training data

### Applications to Social Science
- Provides tool for predicting human behavior in novel experiments
- Could enable exploration of counterfactual scenarios
- Relevant to using AI for social science research

## Key concepts

- **Psych-101**: Large-scale dataset of 160 psychological experiments with 60,000+ participants and 10M+ choices
- **Unified theory of cognition**: Single model explaining diverse cognitive phenomena
- **Foundation model**: Pre-trained model that can be adapted to many tasks
- **Neural alignment**: Correspondence between model representations and brain activity

## Notes

Centaur represents a major advance in computational cognitive science. The Psych-101 dataset is unprecedented in scale, covering diverse cognitive domains. The finding that fine-tuning improves neural alignment is particularly interesting—it suggests that training on behavioral data changes how the model represents information in ways that better match human neural representations. The model's ability to generalise to new tasks and domains suggests it's learning something about general principles of human cognition rather than just memorising specific experiments. This work is directly relevant to discussions of using LLMs as social agents, as it shows that with appropriate training, models can better predict human behavior.
