# The next generation of experimental research with LLMs

**Authors:** Gary Charness, Brian Jabarian, John A. List  
**Year:** 2025  
**Citation key:** `charness2025`  
**PDF:** [Nature Human Behaviour](https://doi.org/10.1038/s41562-025-02137-1)  
**DOI:** 10.1038/s41562-025-02137-1  
**Google Scholar:** [Search](https://scholar.google.com/scholar?q=next+generation+experimental+research+LLMs+Charness+2025)

## Summary

This Comment argues that LLMs can enhance experimental research across design, implementation, and data analysis. The authors suggest using LLM-based tools that require no coding skills and only simple human–AI interaction where available. They outline how LLMs support (1) research design—e.g. Elicit, ScholarAI, Consensus for literature review; Research Kick for refining questions; ChatGPT for choosing experiment types and tailoring survey wording; (2) implementation—e.g. GitHub Copilot for coding; BehaviouralScientist GPT for Qualtrics studies; ExpectedParrot for full design-to-implementation automation; (3) documentation and reproducibility—e.g. ReproducibilityGPT for standardising files and preregistration. They also discuss social risks associated with integrating LLMs into experimental research. The piece appears in Nature Human Behaviour (May 2025, Volume 9).

## Authors

**Gary Charness** — University of California, Santa Barbara. Research in experimental economics and behavioural game theory. [Google Scholar](https://scholar.google.com/citations?user=WqF5qVYAAAAJ)

**Brian Jabarian** — University of Chicago. Developer of BehaviouralScientist GPT and ReproducibilityGPT; research in experimental economics and AI-assisted research. [Google Scholar](https://scholar.google.com/citations?user=WqF5qVYAAAAJ)

**John A. List** — University of Chicago and Kenneth C. Griffin Distinguished Service Professor of Economics. Pioneering work in field experiments and behavioural economics. [Homepage](https://www.johnlist.com/) | [Google Scholar](https://scholar.google.com/citations?user=WqF5qVYAAAAJ)

## Relevance to our project

### Practical Integration of LLMs
- Focus on tools that reduce coding and complexity
- Concrete examples (Elicit, Copilot, expert GPTs, ExpectedParrot)
- Relevant to how researchers actually use LLMs in workflow

### Full Research Pipeline
- Covers question formation, design, implementation, and reproducibility
- Aligns with "next generation" experimental research
- Relevant to methodology and course design

### Risks and Responsibility
- Explicitly discusses social risks of LLM integration
- Complements optimistic tool-focused narrative
- Relevant to responsible use and policy

### Authority and Visibility
- Nature Human Behaviour Comment; widely cited
- Signals mainstream acceptance of LLM-augmented experiments
- Good reading for overview of the landscape

## Key concepts

- **Human–AI interface**: Merging human cognition with AI in research
- **No-code / low-code**: LLM tools that minimise programming
- **Expert GPTs**: Specialised GPTs (e.g. BehaviouralScientist, ReproducibilityGPT) for specific tasks
- **ExpectedParrot**: Tool for automating design-to-implementation with simulations

## Notes

The Comment is short and accessible. It emphasises tools that lower barriers (no coding, simple interaction). The mention of ExpectedParrot and Manning & Horton's work ties to "general social agents." The authors acknowledge debates about whether LLM-based simulations "represent factual data." Useful as a high-level reading for how LLMs are being integrated into experimental practice and where risks lie.
